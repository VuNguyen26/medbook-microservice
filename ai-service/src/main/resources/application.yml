server:
  port: 8089

spring:
  application:
    name: ai-service

  servlet:
    multipart:
      max-file-size: 50MB
      max-request-size: 50MB

  ai:
    openai:
      base-url: https://openrouter.ai/api
      api-key: ${SPRING_AI_OPENAI_API_KEY}

      # ðŸ”¥ Báº®T BUá»˜C KHI DÃ™NG OPENROUTER (yÃªu cáº§u cá»§a OpenRouter)
      http:
        headers:
          HTTP-Referer: "http://localhost"
          X-Title: "MedBook AI Service"

      # ðŸ”¥ MODEL CHAT Há»¢P Lá»† Cá»¦A OPENROUTER
      chat:
        options:
          model: "meta-llama/llama-3.1-8b-instruct"

      # ðŸ”¥ MODEL EMBEDDING Há»¢P Lá»† (OpenRouter há»— trá»£)
      embedding:
        options:
          model: "mixedbread-ai/mxbai-embed-large"
          # CÃ¡c model embedding khÃ¡c cá»§a OpenRouter:
          # model: "mistral/mistral-embed"
          # model: "BAAI/bge-small-en-v1.5"

    vectorstore:
      qdrant:
        host: ${QDRANT_HOST:qdrant}
        port: ${QDRANT_PORT:6334}
        grpc-enabled: true
        collection-name: ${QDRANT_COLLECTION:medbook-ai}
        distance: COSINE

management:
  endpoints:
    web:
      exposure:
        include: "*"
  endpoint:
    health:
      show-details: always

eureka:
  client:
    service-url:
      defaultZone: ${EUREKA_CLIENT_SERVICEURL_DEFAULTZONE:http://discovery-service:8761/eureka/}
    register-with-eureka: true
    fetch-registry: true

  instance:
    prefer-ip-address: true

logging:
  level:
    root: INFO
    org.springframework.web: DEBUG
    com.medbook.aiservice: DEBUG
