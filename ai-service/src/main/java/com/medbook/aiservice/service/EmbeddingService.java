package com.medbook.aiservice.service;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.pdfbox.pdmodel.PDDocument;
import org.apache.pdfbox.text.PDFTextStripper;
import org.springframework.ai.document.Document;
import org.springframework.ai.embedding.EmbeddingModel;
import org.springframework.ai.vectorstore.VectorStore;
import org.springframework.stereotype.Service;
import org.springframework.web.multipart.MultipartFile;

import java.time.Instant;
import java.util.*;

@Service
@RequiredArgsConstructor
@Slf4j
public class EmbeddingService {

    private final EmbeddingModel embeddingModel;
    private final VectorStore vectorStore;

    /**
     * PDF ‚Üí cleaned text ‚Üí smart chunk ‚Üí embeddings ‚Üí Qdrant
     */
    public void ingestPdf(MultipartFile file, String category) {

        if (file.isEmpty()) {
            throw new RuntimeException("File upload r·ªóng");
        }

        try {
            byte[] pdfBytes = file.getBytes();

            String rawText;

            try (PDDocument doc = PDDocument.load(pdfBytes)) {
                PDFTextStripper stripper = new PDFTextStripper();
                rawText = stripper.getText(doc);
            }

            if (rawText == null || rawText.isBlank()) {
                throw new RuntimeException("PDF kh√¥ng c√≥ text (c√≥ th·ªÉ l√† file scan ho·∫∑c b·ªã m√£ ho√°)");
            }

            // 1Ô∏è‚É£ L√†m s·∫°ch text ‚Äî c·ª±c k·ª≥ quan tr·ªçng
            String cleaned = cleanText(rawText);

            // 2Ô∏è‚É£ Chunk th√¥ng minh theo c√¢u
            List<String> chunks = smartChunk(cleaned, 60); // 60 t·ª´ / chunk

            List<Document> documents = new ArrayList<>();

            for (int i = 0; i < chunks.size(); i++) {
                Map<String, Object> metadata = new HashMap<>();
                metadata.put("source", file.getOriginalFilename());
                metadata.put("category", category);
                metadata.put("chunkIndex", i);
                metadata.put("uploadedAt", Instant.now().toString());

                documents.add(new Document(chunks.get(i), metadata));
            }

            vectorStore.add(documents);

            log.info("üìö Ingest PDF '{}': t·ªïng {} chunks",
                    file.getOriginalFilename(), chunks.size());

        } catch (Exception e) {
            log.error("‚ùå L·ªói ingest PDF: {}", file.getOriginalFilename(), e);
            throw new RuntimeException("Kh√¥ng th·ªÉ x·ª≠ l√Ω file PDF: " + e.getMessage());
        }
    }

    /**
     * D·ªçn s·∫°ch text: remove k√Ω t·ª± ·∫©n, multiple spaces, header, bullet l·ªói
     */
    private String cleanText(String text) {

        return text
                .replaceAll("[\\u0000-\\u001F]", " ")     // Remove control chars
                .replaceAll("‚Ä¢", "- ")                   // Fix bullet
                .replaceAll("[‚ñ†‚ñ™‚óÜ‚óè‚ñ°‚ñ†‚óº]", "- ")           // Fix PDF symbols
                .replaceAll("\\s{2,}", " ")              // Multiple spaces
                .replaceAll("\n{2,}", "\n")              // Clean multi newlines
                .trim();
    }

    /**
     * Chunk theo c√¢u ƒë·ªÉ ƒë·∫£m b·∫£o embedding ch√≠nh x√°c
     */
    private List<String> smartChunk(String text, int maxWords) {
        List<String> chunks = new ArrayList<>();

        String[] sentences = text.split("(?<=[.!?‚Ä¶])\\s+"); // t√°ch theo d·∫•u c√¢u

        StringBuilder current = new StringBuilder();
        int count = 0;

        for (String s : sentences) {
            int words = s.split("\\s+").length;

            if (count + words > maxWords) {
                chunks.add(current.toString().trim());
                current.setLength(0);
                count = 0;
            }

            current.append(s).append(" ");
            count += words;
        }

        if (current.length() > 0) chunks.add(current.toString().trim());

        return chunks;
    }
}
